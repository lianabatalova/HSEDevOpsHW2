# HSEDevOpsHW2

**Parallel Dataset Processing**

In this task you need to write a script that will download some dataset in parallel.

Script have to accept these arguments:
- number of workers
- the column in which the data links are located
- folder for saving data
All arguments must be named.

Link to the dataset- https://drive.google.com/file/d/1EfRc2RLVdwWlXWz3nDIBEv_EvvOMd9ip/view?usp=sharing 


**Train val split**

In this task you need to write a script that will divide a .csv dataset into train and validation samples.
You can test your code on the dataset: https://www.kaggle.com/c/titanic 

Script requires 3 arguments:
- input … (path to the dataset)
- train_ratio … (percentage of objects in train sample)
- y_column <column name> (name of the column, where objects class labels are located)
